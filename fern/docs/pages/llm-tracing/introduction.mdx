---
title: Introduction to LLM Tracing
subtitle: Trace your LLM applications and evaluate them on a component level.
slug: llm-tracing-introduction
description: Learn about LLM tracing with Confident AI
---

Confident AI offers **LLM tracing** for teams to trace and monitor LLM applications. Think Datadog for LLM apps, but with an additional suite of 30+ evaluation metrics to track continuous performance over time.

<Tabs>
  <Tab title="Traces">
    You can log a **single-turn LLM interaction** through LLM tracing. Traces
    are a single execution of your LLM app, and running evals on traces is akin
    to the [end-to-end evals](/llm-evaluation-end-to-end-evals) for LLM
    evaluation in development.
    <Frame caption="LLM Tracing: Traces with Evals">
      <video style={{ aspectRatio: "16 / 9", width: "100%" }} controls>
        <source
          src="https://confident-docs.s3.us-east-1.amazonaws.com/llm-tracing:traces.mp4"
          type="video/mp4"
        />
      </video>
    </Frame>
  </Tab>
  <Tab title="Spans">
    Spans are **individual components** such as LLM calls, agents, retrieveres,
    tools, etc. that make up a trace. Running evals on spans is akin to the
    [component-level evals](/llm-evaluation-component-level-evals) for LLM
    evaluation in development.
    <Frame caption="LLM Tracing: Spans with Evals">
      <video style={{ aspectRatio: "16 / 9", width: "100%" }} controls>
        <source
          src="https://confident-docs.s3.us-east-1.amazonaws.com/llm-tracing:spans.mp4"
          type="video/mp4"
        />
      </video>
    </Frame>
  </Tab>
  <Tab title="Threads">
    Threads are **a group of traces**, grouped together via a `thread_id` that
    you provide during tracing. It represents a **multi-turn LLM interaction**,
    and running evals on threads require **multi-turn** metrics, akin to running
    evals on `ConversationalTestCase`s in development.
    <Frame caption="LLM Tracing: Threads with Evals">
      <video style={{ aspectRatio: "16 / 9", width: "100%" }} controls>
        <source
          src="https://confident-docs.s3.us-east-1.amazonaws.com/llm-tracing:threads.mp4"
          type="video/mp4"
        />
      </video>
    </Frame>
  </Tab>
</Tabs>

## Get Started

Get LLM tracing for your LLM app with best in-class-evals.

<CardGroup cols={3}>
  <Card
    title="5 Min Quickstart"
    icon="fa-light fa-bolt"
    iconType="solid"
    href="/llm-tracing-quickstart"
  >
    <div className='absolute top-4 right-4'>
      <Icon icon="arrow-up-right-from-square" />
    </div>

    Start tracing your LLM applications now by following this short quickstart.

  </Card>
  <Card
    title="Online & Offline Evals"
    icon="fa-light fa-toggle-on"
    iconType="solid"
    href="/llm-tracing-evaluations"
  >
    <div className='absolute top-4 right-4'>
      <Icon icon="arrow-up-right-from-square" />
    </div>

    Run online and offline evaluations for your LLM application's traces, spans and threads.

  </Card>
  <Card
    title="Latency and Cost Tracking"
    icon="fa-light fa-stopwatch"
    iconType="solid"
    href="/llm-tracing-latency-cost-tracking"
  >
    <div className='absolute top-4 right-4'>
      <Icon icon="arrow-up-right-from-square" />
    </div>

    Track your LLM application's cost and latency during execution.

  </Card>
</CardGroup>

## Advanced Features

You can configure tracing on Confident AI in virtually any way you wish:

<CardGroup cols={2}>
  <Card
    title="Trace Environments"
    icon="fa-light fa-globe"
    iconType="solid"
    href="/llm-tracing-features-environment"
  >
    <div className='absolute top-4 right-4'>
      <Icon icon="arrow-up-right-from-square" />
    </div>
    Set different trace environments for your app.
  </Card>

{" "}

<Card
  title="Sampling Rate"
  icon="fa-light fa-percent"
  iconType="solid"
  href="/llm-tracing-features-sampling"
>
  <div className="absolute top-4 right-4">
    <Icon icon="arrow-up-right-from-square" />
  </div>
  Configure the trace sampling rate.
</Card>

{" "}

<Card
  title="Any Metadata"
  icon="fa-light fa-brackets-curly"
  iconType="solid"
  href="/llm-tracing-features-metadata"
>
  <div className="absolute top-4 right-4">
    <Icon icon="arrow-up-right-from-square" />
  </div>
  Log any custom metadata with your traces.
</Card>

{" "}

<Card
  title="Tags"
  icon="fa-light fa-tag"
  iconType="solid"
  href="/llm-tracing-features-tags"
>
  <div className="absolute top-4 right-4">
    <Icon icon="arrow-up-right-from-square" />
  </div>
  Log any tags for better trace organization.
</Card>

{" "}

<Card
  title="Threads/Conversations"
  icon="fa-light fa-message-lines"
  iconType="solid"
  href="/llm-tracing-features-threads"
>
  <div className="absolute top-4 right-4">
    <Icon icon="arrow-up-right-from-square" />
  </div>
  Log entire conversations (threads) for multi-turn tracing.
</Card>

{" "}

<Card
  title="Mask PII"
  icon="fa-light fa-eye-slash"
  iconType="solid"
  href="/llm-tracing-features-masking"
>
  <div className="absolute top-4 right-4">
    <Icon icon="arrow-up-right-from-square" />
  </div>
  Mask PII for traces to protect sensitive data.
</Card>

{" "}

<Card
  title="User Tracking"
  icon="fa-light fa-user"
  iconType="solid"
  href="/llm-tracing-features-users"
>
  <div className="absolute top-4 right-4">
    <Icon icon="arrow-up-right-from-square" />
  </div>
  Track user identities or sessions for trace attribution.
</Card>

<Card
  title="Custom Span Types"
  icon="fa-light fa-gear"
  iconType="solid"
  href="/llm-tracing-features-attributes"
>
  <div className='absolute top-4 right-4'>
    <Icon icon="arrow-up-right-from-square" />
  </div>
  Set span and component types for detailed tracing.
</Card>
</CardGroup>

## FAQs

<AccordionGroup>
<Accordion title="What evals are offered by Confident AI LLM tracing?">

You can run evaluations using metrics for **RAG**, **agents**, **chatbots**, on:

1. Traces (end-to-end)
2. Spans (individual components)
3. Threads (multi-turn conversations)

And these are be either done in an **online** fashion (run evals as they are being ingested in the platform), or **offline** (run evals retrospectively).

</Accordion>
<Accordion title="How will tracing affect my app?">

Confident AI tracing is designed to be completely non-intrusive to your application. It:

- Can be disabled/enabled anytime through the `CONFIDENT_TRACING_ENABLED="YES"/"NO"` enviornment variable.
- Requires no rewrite of your existing code - just add the `@observe` decorator.
- Runs asynchronously in the background with zero impact on latency.
- Fails silently if there are any issues, ensuring your app keeps running.
- Works with any function signature - you can set input/output at runtime.

</Accordion>
</AccordionGroup>
