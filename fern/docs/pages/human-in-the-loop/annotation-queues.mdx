---
subtitle: Learn about annotation queues, and how to assign items for team members to annotate
slug: human-in-the-loop/annotation-queues
---

## Overview

Confident AI allows internal, domain experts to leave annotations on traces, spans, and threads in addition to automatic ingestion of user feedback via the Evals API.

You can either leave annotations as an:

- **Ad-hoc** standealone task, or
- As part of an **annotation queue**

Both of the two workflow gives you the same end-result.

<Note>
  "Annotation queues" refer to a group of traces, spans, or threads that are
  pending to be evaluated. It provides an extra layer of abstraction to manage
  annotations from different team members more effectively.
</Note>

## Annotate as a Standalone Task

Leaving annotations as a standealone task is extremely simple and only requires you to navigate to either the the **Traces**, **Spans**, or **Threads** page under the **Observatory**.

Each and every single trace/span/thread you click on will give you the ability to leave scores in the form of:

- A **thumbs up/down**, or
- A **1-5 star rating**

You'll also have the opportunity to leave optional fields such as:

- Explanation
- Expected output (traces and spans)
- Expected outcome (threads)

To understand the difference in traces/spans and thread annotations, read this section on [single vs multi-turn annotations.](/docs/human-in-the-loop/introduction#single-vs-multi-turn)

<Tabs>
  <Tab title="Traces">
    <Frame>
      <video
        src="https://confident-docs.s3.us-east-1.amazonaws.com/annotation:traces.mp4"
        controls
        autoPlay
      />
    </Frame>
  </Tab>
  <Tab title="Spans">
  
   <Frame>
      <video
        src="https://confident-docs.s3.us-east-1.amazonaws.com/annotation:spans.mp4"
        controls
        autoPlay
      />
    </Frame>

  </Tab>
  <Tab title="Threads">
  
   <Frame>
      <video
        src="https://confident-docs.s3.us-east-1.amazonaws.com/annotation:threads.mp4"
        controls
        autoPlay
      />
    </Frame>

  </Tab>
</Tabs>

## Using Annotation Queues

An often preferred way, especially for larger teams that require annotations from domain experts, is to use annotation queues for annotation.

<Tip>
  Annotation queues are basically a group of traces/spans/threads, that are
  pending to be evaluated. It provides annotation teams a more organized and
  streamlined interface to annotate data instead of the ad-hoc approach shown
  above.
</Tip>

There are three types of annotation queues in Confident AI: **Traces**, **Spans**, and **Threads**. This mean that you cannot add threads to an annotation queue that are meant for traces, and vice-versa.

<Steps>

<Step title="Create annotation queue">

First create an annotation queue. In this entire example, we'll be showing an annotation queue for **traces**, but it will be almost identical for spans and threads.

<Warning>
  You **must** click on the **Traces** tab to create a queue for traces. The
  same applies for **Spans** and **Threads**.
</Warning>

<Frame caption="Create Annotation Queue">
  <video
    src="https://confident-docs.s3.us-east-1.amazonaws.com/queues:create-queue.mp4"
    autoPlay
  />
</Frame>

</Step>

<Step title="Add items to queue">

You can add traces, spans, and threads to an annotation queue literally whenever you see one of them on the platform. This mainly includes the **Observatory** for **Traces**, **Spans**, and **Threads**, but also [component-level testing reports](/docs/llm-evaluation/single-turn/end-to-end#llm-tracing-for-local-e2e-testing) where traces and spans are displayed.

You can add to multiple queues at once, and even assign a team member to annotate the items you're queueing.

<Tip>
  If you don't see any avaiable queues to add to, make sure you've created a
  queue **specific to the data you're adding** (e.g. trace queue for traces,
  span queue for spans, and thread queue for threads).
</Tip>

<Frame caption="Add Traces to Queues">
  <video
    src="https://confident-docs.s3.us-east-1.amazonaws.com/queues:add-traces.mp4"
    controls
    autoPlay
  />
</Frame>

</Step>

<Step title="Annotate queued items">

After you've added items into your annotation queue, they will be visible in your annotation queue for annotation:

<Frame caption="Annotate Queued Traces">
  <video
    src="https://confident-docs.s3.us-east-1.amazonaws.com/queues:annotate-items.mp4"
    controls
    autoPlay
  />
</Frame>

You'll have the option to:

- Track completion progress
- Filter for items that are completed, still in progress, or assigned to you
- Auto-mark items as completed when done with annotation
- View full details of traces/spans/threads

By default, the **Queue Annotator** strips away all information that except the input, output, metadata, and turns (for threads).

</Step>

<Step title="Track progress">

Once you're done, go to **Queue Settings** to see an overview of all completed/in progress items.

<Frame>
  <video
    src="https://confident-docs.s3.us-east-1.amazonaws.com/queues:mark-items.mp4"
    controls
    autoPlay
  />
</Frame>

</Step>

</Steps>

## Manage Queued Items

For items that you've queued for annotation, you can always manage them via the **Queue Settings** page, which includes assigning/unnassigning users, marking items as completed/in progress, and removing items from a queue.

<Frame caption="Manage Queue Settings">
  <video
    src="https://confident-docs.s3.us-east-1.amazonaws.com/queues:manage-items.mp4"
    controls
    autoPlay
  />
</Frame>
