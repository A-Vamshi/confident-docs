---
title: Introduction
subtitle: Welcome to Confident AI's Evals API reference.
slug: api-reference/introduction
---

## What is Confident AI's Evals API?

Confident AI enables organizations to offload evaluations, tracing, dataset management, and prompt versioning via a comprehensive RESTFUL **Evals API**.

Whether you're evaluating LLM outputs in production or integrating directly with [DeepEval](https://github.com/confident-ai/deepeval), the platform supports a multi-tenant structure for clean project-level isolation and scalability.

<Tip title="Evaluation metrics via the Evals API are 100% powered by DeepEval">
  DeepEval is one of the most widely adopted LLM evaluation framework in the
  world, with over 10k stars and 20 million daily evaluations.

<Frame background="subtle" caption="⭐ DeepEval Star Growth ⭐">
  [![Star History
  Chart](https://api.star-history.com/svg?repos=confident-ai/deepeval&type=Date)](https://www.star-history.com/#confident-ai/deepeval&Date)
</Frame>

</Tip>

## Features of Evals API

Our Evals API offers a rich set of RESTful endpoints that lets you run online evaluations, create datasets, manage prompts, and more — all without needing Python or TypeScript SDKs in a production environment.

### Get Started

Get started with the Evals API by going through these sections:

<CardGroup cols={3}>
  <Card
    title="Authentication"
    icon="lock-keyhole"
    iconType="solid"
    href="/docs/api-reference/authentication"
  >
    Create a Confident AI account and generate your API keys to start using our services.
  </Card>
  <Card
    title="Data Models"
    icon="table-cells"
    iconType="solid"
    href="/docs/api-reference/data-models"
  >
    Learn about the core data models and terminologies used in the Evals API.
  </Card>
  <Card
    title="Quickstart"
    icon="stopwatch"
    iconType="solid"
    href="/docs/api-reference/quickstart"
  >
    Run your first online evaluation using Confident AI's Evals API in under 5 minutes.
  </Card>
</CardGroup>

### Our Endpoints

Access a full suite of endpoints to manage evaluations, datasets, prompts, traces, and more.

<CardGroup cols={3}>
  <Card
    title="Metric Collections"
    icon="album-collection"
    iconType="solid"
    href="/docs/api-reference/metric-collections/list-metric-collections"
  >
    Create and use metric collections that allow you to run remote evals.
  </Card>
  <Card
    title="Datasets"
    icon="database"
    iconType="solid"
    href="/docs/api-reference/datasets/pull-dataset"
  >
    Store a list of goldens that serve as inputs to evaluate your applications.
  </Card>
  <Card
    title="Evaluation"
    icon="flask"
    iconType="solid"
    href="/docs/api-reference/evaluation/evaluate-llm"
  >
    Evaluate your test cases, traces, spans and threads using our API.
  </Card>
  <Card
    title="Tracing"
    icon="hexagon-nodes"
    iconType="solid"
    href="/docs/api-reference/tracing/get-trace"
  >
    Utilize your application's traces and get full visibility of its workflow.
  </Card>
  <Card
    title="Prompt"
    icon="pen-to-square"
    iconType="solid"
    href="/docs/api-reference/prompt/get-prompt"
  >
    Use prompt templates to iterate and improve your application's performance.
  </Card>
  <Card
    title="Annotations"
    icon="thumbs-up"
    iconType="solid"
    href="/docs/api-reference/annotations/create-annotation"
  >
    Annotate your evaluations with human feedback to meet your goals.
  </Card>
</CardGroup>

## FAQs

<AccordionGroup>

    <Accordion title="How is the Evals API different from DeepEval?">

    The Evals API provides more low-level control over the DeepEval client and provide benefits that DeepEval alone doesn't offer:

    **Managed Infrastructure**: Serverless evaluations on our managed servers, error handling for metric failures and retries, cost management and billing optimization, automatic scaling based on evaluation volume.

    **Platform Dashboard**: Visual results for each customer dataset, historical tracking and trends, team collaboration features, custom analytics dashboards.

    </Accordion>

    <Accordion title="How is the Evals API different from using the platform?">

    The Evals API and platform serve different use cases in your LLM application development workflow:

    **Platform (Dashboard)**: Use when your engineering teams need to improve an LLM application. It provides visual test case creation, interactive evaluation results, team collaboration features, and built-in dashboards.

    **Evals API**: Use when building an LLM application that needs to automate evaluations for different customers, run evaluations programmatically, build custom dashboards, integrate into existing workflows, or scale across multiple customer environments.

    Both approaches use the same underlying evaluation engine, so you can start with the platform for development and use the API for production automation.

    </Accordion>

    <Accordion title="Who is this for?">

    1. Organizations that need to **scale evaluations across multiple customers or environments** while maintaining visibility into results.
    2. Users that aren't working with Python or Typescript. If users are working with either Python or Typescript, using DeepEval as your client library is highly recommended.

    </Accordion>

</AccordionGroup>
